import os
import re
import sys
import subprocess
import hashlib
import datetime
from typing import Optional, Tuple, List, Union

# Third party imports
import requests
from bs4 import BeautifulSoup
import akshare as ak
import pandas as pd
from loguru import logger
from pathlib import Path

def check_match(strA: str, strB: str) -> bool:
    """
    Check if strA contains any matches for regex pattern strB
    
    Args:
        strA: Target string to search
        strB: Regex pattern to match against
        
    Returns:
        bool: True if pattern matches, False otherwise
    """
    # re.search æ‰«ææ•´ä¸ªå­—ç¬¦ä¸²å¹¶è¿”å›ç¬¬ä¸€ä¸ªæˆåŠŸçš„åŒ¹é…ï¼Œå¦‚æœæ²¡æœ‰åŒ¹é…åˆ™è¿”å› None
    if re.search(strB, strA):
        return True
    else:
        return False

def filter_csv(file_path):
    df = pd.read_csv(file_path)

    df2 = df[df['avg_score'] > 0].copy()
    filtered_df = df2[df['pos_ratio'] > 0.8].copy()

    def clean_code(text):
        return "".join(re.findall(r'\d+', str(text)))

    stock_codes = filtered_df['instrument'].apply(clean_code).tolist()

    result_string = ",".join(stock_codes)

    return result_string

def check_match_in_list(strA, regex_list):
    """
    strA: ç›®æ ‡å­—ç¬¦ä¸²
    regex_list: æ­£åˆ™è¡¨è¾¾å¼åˆ—è¡¨ (åŸ strB)
    è¿”å›: å¦‚æœ regex_list ä¸­æœ‰ä»»æ„ä¸€ä¸ªæ­£åˆ™èƒ½åŒ¹é…åˆ° strAï¼Œè¿”å› True
    """
    # åªè¦æœ‰ä¸€ä¸ª pattern èƒ½åœ¨ strA ä¸­ search åˆ°ï¼Œå°±è¿”å› True
    return any(re.search(pattern, strA) for pattern in regex_list)

def get_latest_url(base_url: str) -> str:
    """
    Follow URL redirects to get final download URL
    
    Args:
        base_url: Starting URL that may redirect
        
    Returns: 
        Final resolved URL after following all redirects
        
    Raises:
        requests.HTTPError: If request fails
    """
    response = requests.get(base_url, allow_redirects=True, timeout=(50, 100))
    response.raise_for_status()
    logger.info(f"Final download URL: {response.url}")
    return response.url

def run_command(cmd: str) -> Tuple[int, str, str]:
    """
    Execute shell command and return exit code and output
    
    Args:
        cmd: Shell command string to execute

    Returns:
        Tuple containing:
        - returncode: Exit code (0 = success)
        - stdout: Standard output text  
        - stderr: Standard error text

    Note:
        Uses subprocess.run() which is recommended for Python 3.5+
        shell=True enables shell features like ~ expansion and pipes
    """
    try:
        # subprocess.run æ˜¯ Python 3.5+ æ¨èçš„æ–¹å¼
        # shell=True: å…è®¸ä»¥å­—ç¬¦ä¸²å½¢å¼ä¼ å…¥å‘½ä»¤ï¼Œå¹¶æ”¯æŒ Shell ç‰¹æ€§ï¼ˆå¦‚ ~ å±•å¼€ã€ç®¡é“ | ç­‰ï¼‰
        # capture_output=True: æ•è· stdout å’Œ stderr (Python 3.7+)
        # text=True: å°†è¾“å‡ºè§£ç ä¸ºå­—ç¬¦ä¸² (str)ï¼Œè€Œä¸æ˜¯å­—èŠ‚ (bytes)
        result = subprocess.run(
            cmd, 
            shell=True, 
            capture_output=True, 
            text=True
        )
        
        # è¿”å›ç»“æœ (å»é™¤æœ«å°¾å¤šä½™çš„æ¢è¡Œç¬¦é€šå¸¸æ˜¯ä¸ªå¥½ä¹ æƒ¯ï¼Œå¦‚æœéœ€è¦ä¿ç•™å¯å»æ‰ .strip())
        return result.returncode, result.stdout.strip(), result.stderr.strip()
        
    except Exception as e:
        # å¦‚æœè°ƒç”¨è¿‡ç¨‹ä¸­å‡ºç° Python å±‚é¢çš„å¼‚å¸¸ï¼ˆéå¸¸å°‘è§ï¼Œé€šå¸¸æ˜¯ç¯å¢ƒé—®é¢˜ï¼‰
        return -1, "", str(e)


def calculate_file_sha256(file_path: str) -> Optional[str]:
    """Calculate SHA256 hash of file content
    
    Args:
        file_path: Path to file to hash
        
    Returns:
        str: SHA256 hex digest 
        None: If file not found
        
    Note:
        Uses rb mode to properly handle binary files
    """
    sha256_hash = hashlib.sha256()
    
    try:
        with open(file_path, "rb") as f:
            for byte_block in iter(lambda: f.read(4096), b""):
                sha256_hash.update(byte_block)
        return sha256_hash.hexdigest()
    except FileNotFoundError:
        logger.warning(f"File not found: {file_path}")
        return None

def get_real_github_hash(repo_url: str, target_filename: str) -> Optional[str]:
    """Get SHA256 hash of GitHub release asset
    
    Args:
        repo_url: GitHub release page URL
        target_filename: Exact filename to lookup
        
    Returns:
        str: SHA256 hash string if found
        None: If unable to find hash
    """
    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 "
    }

    try:
        session = requests.Session()
        response = session.get(repo_url, headers=headers)
        response.raise_for_status()
    except Exception as e:
        logger.error(f"Failed to fetch GitHub page: {e}")
        return None

    soup = BeautifulSoup(response.text, 'html.parser')

    # --- å…³é”®æ­¥éª¤ï¼šå¤„ç† GitHub çš„åŠ¨æ€åŠ è½½ (include-fragment) ---
    # GitHub ç°åœ¨é€šå¸¸æŠŠ Assets åˆ—è¡¨æ”¾åœ¨ä¸€ä¸ªç‹¬ç«‹çš„ URL é‡ŒåŠ è½½
    # æˆ‘ä»¬å¯»æ‰¾åŒ…å« "expanded_assets" çš„ include-fragment æ ‡ç­¾
    fragment_tag = soup.find("include-fragment", src=re.compile("expanded_assets"))

    target_soup = soup # é»˜è®¤åœ¨å½“å‰é¡µé¢æ‰¾

    if fragment_tag:
        assets_url = fragment_tag['src']
        # å¦‚æœæ˜¯ç›¸å¯¹è·¯å¾„ï¼Œè¡¥å…¨ä¸ºç»å¯¹è·¯å¾„
        if not assets_url.startswith("http"):
            assets_url = "https://github.com" + assets_url
        
        # print(f"2. æ£€æµ‹åˆ°åŠ¨æ€åŠ è½½ï¼Œæ­£åœ¨è¯·æ±‚èµ„æºåˆ—è¡¨: {assets_url} ...")
        try:
            resp_assets = session.get(assets_url, headers=headers)
            target_soup = BeautifulSoup(resp_assets.text, 'html.parser')
        except Exception as e:
            print(f"âŒ è·å–èµ„æºåˆ—è¡¨å¤±è´¥: {e}")
            return
    else:
        print("â„¹ï¸ æœªæ£€æµ‹åˆ°åŠ¨æ€åŠ è½½ï¼Œå°è¯•åœ¨ä¸»é¡µé¢ç›´æ¥æŸ¥æ‰¾...")

    # --- æŸ¥æ‰¾æ–‡ä»¶å’Œå“ˆå¸Œ ---
    # æŸ¥æ‰¾ href ä»¥æ–‡ä»¶åç»“å°¾çš„é“¾æ¥
    file_link = target_soup.find("a", href=re.compile(re.escape(target_filename) + r"$"))

    if not file_link:
        print(f"âŒ é”™è¯¯: å³ä½¿åœ¨åŠ è½½èµ„æºåˆ—è¡¨åï¼Œä»æœªæ‰¾åˆ° '{target_filename}'ã€‚")
        return

    # print(f"âœ… å·²å®šä½æ–‡ä»¶é“¾æ¥ï¼Œæ­£åœ¨æå–å“ˆå¸Œ...")
    
    # å‘ä¸Šå¯»æ‰¾åŒ…å« clipboard-copy çš„å®¹å™¨
    current_element = file_link.parent
    found_hash = None

    for _ in range(5): # å‘ä¸Šæ‰¾5å±‚
        if not current_element: break
        
        # æŸ¥æ‰¾ value å±æ€§åŒ…å« sha256 çš„å¤åˆ¶æŒ‰é’®
        clipboard = current_element.find("clipboard-copy")
        if clipboard and clipboard.get("value"):
            val = clipboard["value"]
            if "sha256" in val:
                found_hash = val[7:]
                break
        current_element = current_element.parent

    if found_hash:
        return found_hash
        print("\n" + "="*40)
        print(f"æ–‡ä»¶: {target_filename}")
        print(f"å“ˆå¸Œ: {found_hash}")
        print("="*40)
    else:
        print("âš ï¸ æ‰¾åˆ°äº†æ–‡ä»¶ï¼Œä½†åœ¨æ—è¾¹æ²¡æœ‰å‘ç°å“ˆå¸Œå€¼ï¼ˆå¯èƒ½è¯¥æ–‡ä»¶ç±»å‹GitHubæœªè®¡ç®—æ˜¾ç¤ºå“ˆå¸Œï¼‰ã€‚")
        exit(1)


def append_to_file(file_path, content):
    """
    å‘æŒ‡å®šæ–‡ä»¶æœ«å°¾è¿½åŠ å­—ç¬¦ä¸²ã€‚
    
    :param file_path: æ–‡ä»¶è·¯å¾„
    :param content: è¦è¿½åŠ çš„å­—ç¬¦ä¸²å†…å®¹
    """
    try:
        # mode='a' ä»£è¡¨ append (è¿½åŠ æ¨¡å¼)
        # encoding='utf-8' é˜²æ­¢ä¸­æ–‡ä¹±ç 
        with open(file_path, mode='a', encoding='utf-8') as f:
            f.write(content)
        # print(f"æˆåŠŸè¿½åŠ å†…å®¹åˆ°: {file_path}")
    except Exception as e:
        print(f"å†™å…¥å¤±è´¥: {e}")

def process_stock_code_v2(code: str) -> str:
    """Process stock code to standardized format with exchange prefix
    
    Args:
        code: Raw stock code (e.g. '600000', '000001')
        
    Returns:
        str: Standardized code with exchange prefix (e.g. 'SH600000')
        
    Note:
        Supports SH/SZ/BJ exchanges and filters B-shares
    """
    code = str(code)
    
    if code.startswith("6"):  # Shanghai
        return f"SH{code}"
    elif code.startswith(("0", "3")):  # Shenzhen
        return f"SZ{code}"
    elif code.startswith(("8", "4", "920")):  # Beijing
        return f"BJ{code}"
    elif code.startswith("900"):  # Shanghai B-share (filter)
        return f"SH{code}"
    elif code.startswith("200"):  # Shenzhen B-share (filter)
        return f"SZ{code}"
    else:
        return f"unknown{code}"

def get_normalized_stock_list() -> pd.DataFrame:
    """Get normalized stock list from AkShare
    
    Returns:
        DataFrame with normalized stock codes
        
    Note:
        Automatically clears proxy settings before request
    """
    logger.info("Clearing proxy settings...")
    for key in ['HTTP_PROXY', 'HTTPS_PROXY', 'http_proxy', 'https_proxy']:
        if key in os.environ:
            logger.debug(f"Removing {key}")
            del os.environ[key]
    """
    è·å– AkShare æ•°æ®å¹¶ç«‹åˆ»æ ‡å‡†åŒ–çš„å®Œæ•´æµç¨‹
    """
    print("æ­£åœ¨ä» AkShare æ‹‰å–å®æ—¶è¡Œæƒ…...")
    try:
        df = ak.stock_info_a_code_name()
        # df = ak.stock_zh_a_spot()
        data = df['code'].apply(process_stock_code_v2)
        df['code'] = data
        # print(df)
        return df
    except Exception as e:
        logger.error(f"è·å–è‚¡ç¥¨åˆ—è¡¨å¤±è´¥: {e}")
        return None

def get_latest_trade_date_ak():
    # 1. è·å–æ–°æµªè´¢ç»çš„äº¤æ˜“æ—¥å†
    # è¿™ä¸ªæ¥å£è¿”å›çš„æ˜¯å†å²ä¸Šæ‰€æœ‰äº¤æ˜“æ—¥ï¼ˆå«ä»Šå¤©ï¼‰
    trade_calendar = ak.tool_trade_date_hist_sina()
    trade_days = trade_calendar['trade_date'].tolist()

    # è½¬æ¢ä¸º datetime.date æ–¹ä¾¿æ¯”è¾ƒ
    # trade_days å·²ç»æ˜¯ datetime.date æ ¼å¼

    now = datetime.datetime.now()
    today = now.date()
    current_hour = now.hour

    # 2. æ‰¾åˆ°ä»Šå¤©åœ¨æ—¥å†ä¸­çš„ä½ç½®ï¼ˆæˆ–ä»Šå¤©ä¹‹å‰çš„æœ€åä¸€ä¸ªäº¤æ˜“æ—¥ï¼‰
    # è¿‡æ»¤æ‰æœªæ¥çš„æ—¥æœŸ
    past_trade_days = [d for d in trade_days if d <= today]

    if not past_trade_days:
        return None

    last_trade_day = past_trade_days[-1]

    # 3. åˆ¤æ–­é€»è¾‘
    if today == last_trade_day:
        # å¦‚æœä»Šå¤©æ˜¯äº¤æ˜“æ—¥ï¼Œåˆ¤æ–­æ˜¯å¦å·²ç»æ”¶ç›˜ (Aè‚¡15:00æ”¶ç›˜)
        # è€ƒè™‘åˆ°æ•°æ®åŒæ­¥å»¶è¿Ÿï¼Œé€šå¸¸å»ºè®®è®¾ä¸º 15:05 æˆ– 15:10
        if current_hour < 15:
            # å°šæœªæ”¶ç›˜ï¼Œå–ä¸Šä¸€ä¸ªäº¤æ˜“æ—¥
            return past_trade_days[-2]
        else:
            # å·²ç»æ”¶ç›˜ï¼Œä»Šå¤©å°±æ˜¯â€œä¸Šä¸€ä¸ªå·²æ”¶ç›˜äº¤æ˜“æ—¥â€
            return last_trade_day
    else:
        # ä»Šå¤©ä¸æ˜¯äº¤æ˜“æ—¥ï¼ˆå‘¨æœ«æˆ–èŠ‚å‡æ—¥ï¼‰ï¼Œç›´æ¥è¿”å›æœ€è¿‘çš„ä¸€ä¸ª
        return last_trade_day


def get_local_data_date(provider_uri):
    code, stdout, stderr = run_command(f"tail -n 1 {provider_uri}/calendars/day.txt")
    return stdout

def fix_mlflow_paths(mlruns_dir=None):
    """
    ç²¾å‡†æ›¿æ¢ MLflow é…ç½®æ–‡ä»¶ä¸­çš„ç”¨æˆ·å®¶ç›®å½•å‰ç¼€ã€‚
    ä»…ä¿®æ”¹ 'file:///home/xxx/' éƒ¨åˆ†ï¼Œä¿ç•™åç»­çš„æ‰€æœ‰å­è·¯å¾„ç»“æ„ã€‚
    """
    # 1. è·å–å½“å‰ç¯å¢ƒçš„ home è·¯å¾„
    current_home = str(Path.home())
    # æ„é€ å½“å‰ç¯å¢ƒçš„ file åè®®å‰ç¼€
    current_prefix = f"file://{current_home}"

    if mlruns_dir is None:
        mlruns_dir = os.path.join(current_home, ".qlibAssistant", "mlruns")

    base_path = Path(mlruns_dir).expanduser().resolve()

    if not base_path.exists():
        print(f"âš ï¸ æœªå‘ç°ç›®å½•: {base_path}")
        return

    print(f"ğŸ” æ­£åœ¨æ‰§è¡Œå‰ç¼€ç²¾å‡†ä¿®å¤...")
    print(f"ğŸ  å½“å‰ Home è·¯å¾„: {current_home}")

    fix_count = 0
    # æ­£åˆ™è¡¨è¾¾å¼è§£é‡Šï¼š
    # åŒ¹é… artifact_location æˆ– artifact_uri å¼€å¤´
    # åé¢è·Ÿç€ file:///home/[ä»»ä½•ä¸åŒ…å«æ–œæ çš„ç”¨æˆ·å]/
    # å¹¶æ•è·åç»­çš„æ‰€æœ‰å†…å®¹ (.*)
    pattern = re.compile(r"^(artifact_(?:location|uri)):\s+file:///home/[^/]+/(.*)")

    for root, _, files in os.walk(base_path):
        if "meta.yaml" in files:
            yaml_path = os.path.join(root, "meta.yaml")

            try:
                with open(yaml_path, "r", encoding="utf-8") as f:
                    content = f.read()

                # ä½¿ç”¨æ­£åˆ™è¿›è¡Œæ›¿æ¢
                # \1 æ˜¯ç¬¬ä¸€ä¸ªæ‹¬å· (é”®å), \2 æ˜¯ç¬¬äºŒä¸ªæ‹¬å· (å®¶ç›®å½•ä¹‹åçš„å‰©ä½™è·¯å¾„)
                # æ„é€ å‡ºï¼šé”®å: file:///home/{å½“å‰ç”¨æˆ·}/{å‰©ä½™è·¯å¾„}
                new_content, count = pattern.subn(rf"\1: {current_prefix}/\2", content)

                if count > 0:
                    with open(yaml_path, "w", encoding="utf-8") as f:
                        f.write(new_content)
                    fix_count += count

            except Exception as e:
                print(f"âŒ ä¿®å¤é”™è¯¯ {yaml_path}: {e}")

    if fix_count > 0:
        print(f"âœ… è·¯å¾„ä¿®å¤å®Œæˆï¼å…±ç²¾å‡†æ›¿æ¢ {fix_count} å¤„å‰ç¼€ã€‚")
    else:
        print("âœ¨ æ£€æŸ¥å®Œæ¯•ï¼šè·¯å¾„å‰ç¼€å·²åŒ¹é…å½“å‰ç³»ç»Ÿï¼Œæ— éœ€ä¿®æ”¹ã€‚")